{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import statistics\n",
    "from torch import relu, tanh, sigmoid\n",
    "from typing import Tuple\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import product\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_x_fnc() -> np.ndarray:\n",
    "    X_1 = np.random.binomial(n = 1, p = 0.5, size = 1)\n",
    "    X_2 = np.random.normal(loc = 1, size=1) #loc (mean) should be higher because we want X to be distributed around positive numbers\n",
    "    \n",
    "    return X_1, X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_u_fnc(u_dim:int) -> np.ndarray:\n",
    "    U = np.random.normal(size = (u_dim))\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_gammas_fnc() -> Tuple[np.ndarray]:\n",
    "    gamma0  = gamma0\n",
    "    gamma_X1 = gamma_X1\n",
    "    gamma_X2 = gamma_X1\n",
    "    gamma_U = gamma_X1\n",
    "    return gamma_X1, gamma_X2, gamma_U, gamma0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_y_fnc(X_1, X_2, U, gamma_X1, gamma_X2, gamma_U, gamma0) -> int:\n",
    "    p_y = sigmoid(torch.tensor(gamma0 + gamma_X1 * X_1 + gamma_X2 * X_2 + gamma_U * U)).numpy()\n",
    "    assert 0 < p_y < 1\n",
    "    Y = np.random.binomial(n=1, p=p_y)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_z_fnc(X_1, X_2, W, b, stddev, nonlinearity: str = 'relu') -> np.ndarray:\n",
    "    \n",
    "    X = np.concatenate([X_1, X_2])\n",
    "\n",
    "    in_dim = X.shape[0]\n",
    "    out_dim = W.shape[0]\n",
    "    \n",
    "    assert W.shape == (out_dim, in_dim)\n",
    "    assert b.shape[0] == out_dim\n",
    "    \n",
    "    pre_nonlinearity = np.matmul(W, X) + b\n",
    "\n",
    "    if nonlinearity == 'relu':\n",
    "        Z_mean = relu(torch.tensor(pre_nonlinearity)).numpy()\n",
    "    elif nonlinearity == 'tanh':\n",
    "        Z_mean = tanh(torch.tensor(pre_nonlinearity)).numpy()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Requested nonlinearity {nonlinearity} is not implemented yet.')\n",
    "\n",
    "    Z = np.random.normal(loc=Z_mean, scale=stddev)\n",
    "    assert Z.shape[0] == out_dim\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_W_and_b_fnc(x_dim: int, z_dim: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "     assert x_dim > 1\n",
    "    \n",
    "     W11 = W[0, 0]\n",
    "     W21 = W[1, 0]\n",
    "     W31 = W[2, 0]\n",
    "     W12 = W[0, 1]\n",
    "     W22 = W[1, 1]\n",
    "     W32 = W[2, 1]\n",
    "    \n",
    "    \n",
    "     W = np.array([\n",
    "      [W11, W12],\n",
    "      [W21, W22],\n",
    "      [W31, W32], \n",
    "    ])\n",
    "    \n",
    "    \n",
    "     b1 = b1\n",
    "     b2 = b2\n",
    "     b3 = b3\n",
    "    \n",
    "     b = np.array([b1, b2, b3])\n",
    "    \n",
    "     W = (z_dim, x_dim)\n",
    "     b = (z_dim)\n",
    "   \n",
    "    \n",
    "     return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data_fnc(N_test,  \n",
    "                           W,\n",
    "                           b,\n",
    "                           gamma0,\n",
    "                           gamma_X1,\n",
    "                           gamma_X2,\n",
    "                           gamma_U,\n",
    "                           stddev) -> None:\n",
    "       \n",
    "    x_dim = 2\n",
    "    z_dim = 3\n",
    "    u_dim = 1\n",
    "    \n",
    "    column_headers = [f'X_{i}' for i in range(x_dim)] + [f'Z_{i}' for i in range(z_dim)] + ['U', 'Y']\n",
    "    print(f'Column names will be {column_headers}')\n",
    "    #output_file = open(output_path, 'w')\n",
    "   \n",
    "    #output_file.write(','.join(column_headers) + '\\n')\n",
    "    return_array = []\n",
    "    \n",
    "   \n",
    "    \n",
    "    for n in range(N_test):\n",
    "           X = generate_x_fnc()\n",
    "           U = generate_u_fnc(u_dim)\n",
    "           Z = generate_z_fnc(X_1 = X[0], X_2 = X[1], W = W, b = b, nonlinearity = 'relu', stddev = stddev)\n",
    "           Y = generate_y_fnc(X_1 = X[0], X_2 = X[1], U = U, gamma0 = gamma0, gamma_X1 = gamma_X1, gamma_X2 = gamma_X2, gamma_U = gamma_U)\n",
    "           \n",
    "        # Concatenate these together\n",
    "           output_line_test = np.concatenate([X[0], X[1], U, Z, Y]).tolist()\n",
    "           return_array.append(output_line_test)\n",
    "        # Turn them into string-values\n",
    "           output_line_test = [str(val) for val in output_line_test]\n",
    "        # Combine them into a comma-separated llist\n",
    "           output_line_test = ','.join(output_line_test)\n",
    "        # Write to file and add newline\n",
    "           #output_file.write(output_line + '\\n')\n",
    "        \n",
    "    #output_file.close()\n",
    "    #print(f'Wrote {N_test} lines to {output_path}')\n",
    "    \n",
    "    return np.array(return_array)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_R1_fnc(R1_prev, Z_11, Z_12, Z_22, U, beta0, beta_X1, beta_X2, beta_U) -> Tuple[np.ndarray]:\n",
    "    \n",
    "    Z_11 = Z_11\n",
    "    Z_12 = Z_12\n",
    "    Z_22 = Z_22\n",
    "    U = U\n",
    "    beta0 = beta0\n",
    "    beta_X1 = beta_X1\n",
    "    beta_X2 = beta_X2\n",
    "    beta_U = beta_U\n",
    "    \n",
    "    if np.random.random() > R1_prev:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_z_star_fnc(Z, R_1) -> Tuple[np.ndarray]:\n",
    "    \n",
    " Z_star_11 = Z[0] if R_1 == 1 else np.nan\n",
    "           \n",
    " Z_star_12 = Z[1] if R_1 == 1 else np.nan\n",
    "           \n",
    " Z_star_22 = Z[2] \n",
    "\n",
    " return Z_star_11, Z_star_12, Z_star_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_betas_fnc() -> Tuple[np.ndarray]:\n",
    "    \n",
    "    beta0 = beta0\n",
    "    beta_X1 = beta_X1\n",
    "    beta_X2 = beta_X2\n",
    "    beta_U = beta_U\n",
    "    \n",
    "    return beta0, beta_X1, beta_X2, beta_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_and_vali_data_fnc(N_train,\n",
    "                                     N_vali,\n",
    "                                     W,\n",
    "                                     b,\n",
    "                                     R1_prev,\n",
    "                                     beta0,\n",
    "                                     beta_X1,\n",
    "                                     beta_X2,\n",
    "                                     beta_U,\n",
    "                                     gamma0,\n",
    "                                     gamma_X1,\n",
    "                                     gamma_X2,\n",
    "                                     gamma_U,\n",
    "                                     stddev) -> None:\n",
    "       \n",
    "    x_dim = 2\n",
    "    z_dim = 3\n",
    "    z_star_dim = 3\n",
    "    u_dim = 1\n",
    "    \n",
    "    \n",
    "    column_headers = [f'X_{i}' for i in range(x_dim)] + [f'Z_{i}' for i in range(z_dim)] + [f'Z_star_{i}' for i in range(z_star_dim)] + ['U', 'Y']\n",
    "    print(f'Column names will be {column_headers}')\n",
    "    #output_file = open(output_path, 'w')\n",
    "   \n",
    "    #output_file.write(','.join(column_headers) + '\\n')\n",
    "    train_data = []\n",
    "    vali_data = []\n",
    "    \n",
    "    \n",
    "    for n in range(N_train):\n",
    "           X = generate_x_fnc()\n",
    "           U = generate_u_fnc(u_dim)\n",
    "           Z = generate_z_fnc(X_1 = X[0], X_2 = X[1], W = W, b=b, nonlinearity = 'relu', stddev = stddev)\n",
    "           Y = generate_y_fnc(X_1 = X[0], X_2 = X[1], U = U, gamma0 = gamma0, gamma_X1 = gamma_X1, gamma_X2 = gamma_X2, gamma_U = gamma_U)\n",
    "           R_1 = generate_R1_fnc(R1_prev, Z_11 = Z[0], Z_12 = Z[1], Z_22 = Z[2], U = U, beta0 = beta0, beta_X1 = beta_X1, beta_X2 = beta_X2, beta_U = beta_U)\n",
    "           \n",
    "           \n",
    "           Z_star_11 = Z[0] if R_1 == 1 else np.nan\n",
    "           \n",
    "           Z_star_12 = Z[1] if R_1 == 1 else np.nan\n",
    "           \n",
    "           Z_star_22 = Z[2] \n",
    "           \n",
    "           Z_star = np.array([Z_star_11, Z_star_12, Z_star_22])\n",
    "    \n",
    "        # Concatenate these together\n",
    "           output_line_train = np.concatenate([X[0], X[1], U, Z, Z_star, Y]).tolist()\n",
    "           train_data.append(output_line_train)\n",
    "           #train_data = return_array.append(output_line)\n",
    "        # Turn them into string-values\n",
    "           #output_line = [str(val) for val in output_line]\n",
    "        # Combine them into a comma-separated list\n",
    "           #output_line = ','.join(output_line)\n",
    "        # Write to file and add newline\n",
    "           #output_file.write(output_line + '\\n')\n",
    "    \n",
    "    for n in range(N_vali):\n",
    "           X = generate_x_fnc()\n",
    "           U = generate_u_fnc(u_dim)\n",
    "           Z = generate_z_fnc(X_1 = X[0], X_2 = X[1], W = W, b=b, nonlinearity = 'relu', stddev = stddev)\n",
    "           Y = generate_y_fnc(X_1 = X[0], X_2 = X[1], U = U, gamma0 = gamma0, gamma_X1 = gamma_X1, gamma_X2 = gamma_X2, gamma_U = gamma_U)\n",
    "           R_1 = generate_R1_fnc(R1_prev, Z_11 = Z[0], Z_12 = Z[1], Z_22 = Z[2], U = U, beta0 = beta0, beta_X1 = beta_X1, beta_X2 = beta_X2, beta_U = beta_U)\n",
    "           #Z_star = generate_z_star_fnc()\n",
    "           \n",
    "           Z_star_11 = Z[0] if R_1 == 1 else np.nan\n",
    "           \n",
    "           Z_star_12 = Z[1] if R_1 == 1 else np.nan\n",
    "           \n",
    "           Z_star_22 = Z[2] \n",
    "           \n",
    "           Z_star = np.array([Z_star_11, Z_star_12, Z_star_22])\n",
    "        \n",
    "           output_line_vali = np.concatenate([X[0], X[1], U, Z, Z_star, Y]).tolist()\n",
    "           vali_data.append(output_line_vali)\n",
    "           #vali_data = return_array.append(output_line)\n",
    "    #output_file.close()\n",
    "    #print(f'Wrote {N} lines to {output_path}')\n",
    "    return np.array(train_data), np.array(vali_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mice_imputation_fnc(train_data, vali_data, **kwargs):\n",
    "    \n",
    " mice_imputer = IterativeImputer(missing_values=np.nan, sample_posterior=True, **kwargs)\n",
    " mice_train_data = mice_imputer.fit_transform(train_data)\n",
    " mice_vali_data = mice_imputer.transform(vali_data)\n",
    "    \n",
    " return mice_train_data, mice_vali_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputation_fnc(train_data, vali_data):\n",
    "    \n",
    "    mean_imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean', verbose=0) #verbose = 0 means the columns and =1 means the rows\n",
    "\n",
    "    mean_train_data = mean_imputer.fit_transform(train_data)\n",
    "    mean_vali_data = mean_imputer.transform(vali_data)\n",
    "\n",
    "    return mean_train_data, mean_vali_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target_measures_fnc(Y, predicted_risks):\n",
    "    \n",
    "    #-------------- Calculate Brier Score--------------------\n",
    "    Brier = brier_score_loss(y_true = Y, y_prob = predicted_risks)\n",
    "    \n",
    "    #-------------- Calibration plot ------------------------\n",
    "    Cal_Plot = calibration_curve(y_true = Y, y_prob = predicted_risks)\n",
    "    \n",
    "    \n",
    "    #-------------- Calculate Observed VS Expected ratio-----\n",
    "    observed_outcome = statistics.mean(Y)\n",
    "    expected_outcome = statistics.mean(predicted_risks)\n",
    "    O_E = observed_outcome / expected_outcome\n",
    "    \n",
    "    #-------------- AUROC -----------------------------------\n",
    "    AUC = metrics.roc_auc_score(y_true = Y, y_score = predicted_risks)\n",
    "    \n",
    "    \n",
    "    #-------------- create a dataframe with all the target measures--------\n",
    "    target_measures = (Cal_Plot, O_E, AUC, Brier)\n",
    "    \n",
    "    #Target_Measures = pd.DataFrame(data = target_measures)\n",
    "    \n",
    "    \n",
    "    return target_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LR_and_get_predictions_fnc(mice_train_data, mice_vali_data, test_data):\n",
    "    \n",
    "    df_train = mice_train_data\n",
    "    df_vali = mice_vali_data\n",
    "    test_data = test_data\n",
    "    \n",
    "    #-------------- fit a LogReg to the imputed train data --------------------\n",
    "    \n",
    "    Z_star_train = df_train[[col for col in df_train if 'Z_star_' in col]].values\n",
    "    Y_train = df_train['Y'].values\n",
    "    print(f'Prevalence of Y_train: {Y_train.mean()}')\n",
    "    \n",
    "    clf = LogisticRegression(penalty='none', random_state=0)\n",
    "    clf.fit(Z_star_train, Y_train)\n",
    "    accuracy = clf.score(Z_star_train, Y_train)\n",
    "    print(f'Accuracy using Z_train: {accuracy}')\n",
    "    \n",
    "    LR_Y_hat_train = clf.predict_proba(Z_star_train)[:, 1]\n",
    "    target_measures_train = calculate_target_measures_fnc(Y = Y_train, predicted_risks = LR_Y_hat_train)\n",
    "    target_measures_train = {\n",
    "        \"dataset\": \"train\",\n",
    "        \"model\": \"LR\",\n",
    "        \"Cal_Plot\": target_measures_train[0],\n",
    "        \"O_E\": target_measures_train[1],\n",
    "        \"AUC\": target_measures_train[2],\n",
    "        \"Brier\": target_measures_train[3] \n",
    "    }\n",
    "    #------------- evaluate the performance of LogReg on the mice imputed vali data -----------------\n",
    "    \n",
    "    Z_star_vali = df_vali[[col for col in df_vali if 'Z_star_' in col]].values\n",
    "    Y_vali = df_vali['Y'].values\n",
    "    print(f'Prevalence of Y_vali: {Y_vali.mean()}')\n",
    "    \n",
    "    #clf = LogisticRegression(penalty='none', random_state=0)\n",
    "    #clf.fit(Z_star_vali, Y_vali)\n",
    "    accuracy = clf.score(Z_star_vali, Y_vali)\n",
    "    print(f'Accuracy using Z_vali: {accuracy}')\n",
    "    \n",
    "    LR_Y_hat_vali = clf.predict_proba(Z_star_vali)[:, 1]\n",
    "    target_measures_vali = calculate_target_measures_fnc(Y = Y_vali, predicted_risks = LR_Y_hat_vali)\n",
    "    target_measures_vali = {\n",
    "        \"dataset\": \"vali\",\n",
    "        \"model\": \"LR\",\n",
    "        \"Cal_Plot\": target_measures_vali[0],\n",
    "        \"O_E\": target_measures_vali[1],\n",
    "        \"AUC\": target_measures_vali[2],\n",
    "        \"Brier\": target_measures_vali[3] \n",
    "    }\n",
    "    #--------------- evaluate the performance of a LogReg on the mice imputed vali data ------------------\n",
    "     \n",
    "    Z_test = test_data[[col for col in test_data if 'Z_' in col]].values\n",
    "    Y_test = test_data['Y'].values\n",
    "    print(f'Prevalence of Y_test: {Y_test.mean()}')\n",
    "    \n",
    "    #clf = LogisticRegression(penalty='none', random_state=0)\n",
    "    #clf.fit(Z_test, Y_test)\n",
    "    accuracy = clf.score(Z_test, Y_test)\n",
    "    print(f'Accuracy using Z_test: {accuracy}')\n",
    "    \n",
    "    LR_Y_hat_test = clf.predict_proba(Z_test)[:, 1]\n",
    "    target_measures_test = calculate_target_measures_fnc(Y = Y_test, predicted_risks = LR_Y_hat_test)\n",
    "    target_measures_test = {\n",
    "        \"dataset\": \"test\",\n",
    "        \"model\": \"LR\",\n",
    "        \"Cal_Plot\": target_measures_test[0],\n",
    "        \"O_E\": target_measures_test[1],\n",
    "        \"AUC\": target_measures_test[2],\n",
    "        \"Brier\": target_measures_test[3] \n",
    "    }\n",
    "    \n",
    "    return [target_measures_train, target_measures_vali, target_measures_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF_and_get_predictions_fnc(train_data, vali_data, test_data):\n",
    "    df_train = train_data\n",
    "    df_vali = vali_data\n",
    "    test_data = test_data\n",
    "    \n",
    "    #-------------- train a RandomForest on the train data --------------------\n",
    "    Z_star_train = df_train[[col for col in df_train if 'Z_star_' in col]].values\n",
    "    Y_train = df_train['Y'].values\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(Z_star_train, Y_train)\n",
    "    \n",
    "    RF_Y_hat_train = clf.predict_proba(Z_star_train)[:, 1]\n",
    "    target_measures_train = calculate_target_measures_fnc(Y = Y_train, predicted_risks = RF_Y_hat_train)\n",
    "    target_measures_train = {\n",
    "        \"dataset\": \"train\",\n",
    "        \"model\": \"RF\",\n",
    "        \"Cal_Plot\": target_measures_train[0],\n",
    "        \"O_E\": target_measures_train[1],\n",
    "        \"AUC\": target_measures_train[2],\n",
    "        \"Brier\": target_measures_train[3] \n",
    "    }\n",
    "    \n",
    "    #-------------- evaluate the performance of a RandomForest on the validation data --------------------\n",
    "    Z_star_vali = df_vali[[col for col in df_train if 'Z_star_' in col]].values\n",
    "    Y_vali = df_vali['Y'].values\n",
    "    \n",
    "    #clf = RandomForestClassifier()\n",
    "    #clf.fit(Z_star_vali, Y_vali)\n",
    "    \n",
    "    RF_Y_hat_vali = clf.predict_proba(Z_star_vali)[:, 1]\n",
    "    target_measures_vali = calculate_target_measures_fnc(Y = Y_vali, predicted_risks = RF_Y_hat_vali)\n",
    "    target_measures_vali = {\n",
    "        \"dataset\": \"vali\",\n",
    "        \"model\": \"RF\",\n",
    "        \"Cal_Plot\": target_measures_vali[0],\n",
    "        \"O_E\": target_measures_vali[1],\n",
    "        \"AUC\": target_measures_vali[2],\n",
    "        \"Brier\": target_measures_vali[3] \n",
    "    }\n",
    "    \n",
    "    #-------------- evaluate the performance a RandomForest on the test data --------------------\n",
    "    Z_test = test_data[[col for col in test_data if 'Z_' in col]].values\n",
    "    Y_test = test_data['Y'].values\n",
    "    \n",
    "    #clf = RandomForestClassifier()\n",
    "    #clf.fit(Z_test, Y_test)\n",
    "    \n",
    "    RF_Y_hat_test = clf.predict_proba(Z_test)[:, 1]\n",
    "    target_measures_test = calculate_target_measures_fnc(Y = Y_test, predicted_risks = RF_Y_hat_test)\n",
    "    target_measures_test = {\n",
    "        \"dataset\": \"test\",\n",
    "        \"model\": \"RF\",\n",
    "        \"Cal_Plot\": target_measures_test[0],\n",
    "        \"O_E\": target_measures_test[1],\n",
    "        \"AUC\": target_measures_test[2],\n",
    "        \"Brier\": target_measures_test[3] \n",
    "    }\n",
    "    \n",
    "    \n",
    "    return [target_measures_train, target_measures_vali, target_measures_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_BT_and_get_predictions_fnc(train_data, vali_data, test_data):\n",
    "    df_train = train_data\n",
    "    df_vali = vali_data\n",
    "    test_data = test_data\n",
    "    \n",
    "    #-------------- train a RandomForest on the train data --------------------\n",
    "    Z_star_train = df_train[[col for col in df_train if 'Z_star_' in col]].values\n",
    "    Y_train = df_train['Y'].values\n",
    "    \n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(Z_star_train, Y_train)\n",
    "    \n",
    "    BT_Y_hat_train = clf.predict_proba(Z_star_train)[:, 1]\n",
    "    target_measures_train = calculate_target_measures_fnc(Y = Y_train, predicted_risks = BT_Y_hat_train)\n",
    "    target_measures_train = {\n",
    "        \"dataset\": \"train\",\n",
    "        \"model\": \"BT\",\n",
    "        \"Cal_Plot\": target_measures_train[0],\n",
    "        \"O_E\": target_measures_train[1],\n",
    "        \"AUC\": target_measures_train[2],\n",
    "        \"Brier\": target_measures_train[3] \n",
    "    }\n",
    "    \n",
    "    #-------------- evaluate the performance a Gradient Boosting Tree on the validation data --------------------\n",
    "    Z_star_vali = df_vali[[col for col in df_train if 'Z_star_' in col]].values\n",
    "    Y_vali = df_vali['Y'].values\n",
    "    \n",
    "    BT_Y_hat_vali = clf.predict_proba(Z_star_vali)[:, 1]\n",
    "    target_measures_vali = calculate_target_measures_fnc(Y = Y_vali, predicted_risks = BT_Y_hat_vali)\n",
    "    target_measures_vali = {\n",
    "        \"dataset\": \"vali\",\n",
    "        \"model\": \"BT\",\n",
    "        \"Cal_Plot\": target_measures_vali[0],\n",
    "        \"O_E\": target_measures_vali[1],\n",
    "        \"AUC\": target_measures_vali[2],\n",
    "        \"Brier\": target_measures_vali[3] \n",
    "    }\n",
    "    #-------------- evaluate the performance of a Gradient Boosting Tree on the test data --------------------\n",
    "    Z_test = test_data[[col for col in test_data if 'Z_' in col]].values\n",
    "    Y_test = test_data['Y'].values\n",
    "    \n",
    "    BT_Y_hat_test = clf.predict_proba(Z_test)[:, 1]\n",
    "    target_measures_test = calculate_target_measures_fnc(Y = Y_test, predicted_risks = BT_Y_hat_test)\n",
    "    target_measures_test = {\n",
    "        \"dataset\": \"test\",\n",
    "        \"model\": \"BT\",\n",
    "        \"Cal_Plot\": target_measures_test[0],\n",
    "        \"O_E\": target_measures_test[1],\n",
    "        \"AUC\": target_measures_test[2],\n",
    "        \"Brier\": target_measures_test[3] \n",
    "    }\n",
    "    \n",
    "    return [target_measures_train, target_measures_vali, target_measures_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_run_fnc(N_test,\n",
    "                   N_train,\n",
    "                   N_vali,\n",
    "                   gamma0,\n",
    "                   gamma_X1,\n",
    "                   gamma_X2,\n",
    "                   gamma_U, \n",
    "                   W,\n",
    "                   b,\n",
    "                   R1_prev,\n",
    "                   beta0,\n",
    "                   beta_X1,\n",
    "                   beta_X2,\n",
    "                   beta_U,\n",
    "                   stddev):\n",
    "    \n",
    "    \n",
    "    \n",
    "    #W, b = turn_W_and_b_into_arrays(W11, W21, W21, ...)\n",
    "\n",
    "    test_data = generate_test_data_fnc(N_test = N_test, W=W, b=b, gamma0 = gamma0, gamma_X1 = gamma_X1, gamma_X2 = gamma_X2, gamma_U = gamma_U, stddev = stddev)\n",
    "    train_data, vali_data = generate_train_and_vali_data_fnc(N_train = N_train, N_vali = N_vali, W=W, b=b, gamma0 = gamma0, gamma_X1 = gamma_X1, gamma_X2 = gamma_X2, gamma_U = gamma_U, R1_prev = R1_prev, beta0 = beta0, beta_X1 = beta_X1, beta_X2 = beta_X2, beta_U = beta_U, stddev = stddev)\n",
    "    \n",
    "    \n",
    "    mice_train_data, mice_vali_data = mice_imputation_fnc(train_data = train_data, vali_data = vali_data)\n",
    "    mean_train_data, mean_vali_data = mean_imputation_fnc(train_data = train_data, vali_data = vali_data)\n",
    "    \n",
    "    x_train_data = train_data[..., :-1] #all the columns excluding Y\n",
    "    x_vali_data = vali_data[..., :-1]\n",
    "    x_mice_train_data, x_mice_vali_data = mice_imputation_fnc(x_train_data, x_vali_data, random_state=0, max_iter=10)\n",
    "\n",
    "    # Concatenate imputed data and labels.\n",
    "    mice_train_data = np.zeros_like(train_data)\n",
    "    mice_train_data[..., :-1] = x_mice_train_data\n",
    "    mice_train_data[..., -1] = train_data[..., -1]\n",
    "\n",
    "    mice_vali_data = np.zeros_like(vali_data) #create an empty array to store the new dataset\n",
    "    mice_vali_data[..., :-1] = x_mice_vali_data\n",
    "    mice_vali_data[..., -1] = vali_data[..., -1]\n",
    "\n",
    "    mean_train_data = pd.DataFrame(mean_train_data, columns=['X_1','X_2','Z_1','Z_2','Z_3','Z_star_1','Z_star_2','Z_star_3','U','Y'])\n",
    "    mean_vali_data = pd.DataFrame(mean_vali_data, columns=['X_1','X_2','Z_1','Z_2','Z_3','Z_star_1','Z_star_2','Z_star_3','U','Y'])\n",
    "\n",
    "\n",
    "    mice_train_data = pd.DataFrame(mice_train_data, columns=['X_1','X_2','Z_1','Z_2','Z_3','Z_star_1','Z_star_2','Z_star_3','U','Y'])\n",
    "    mice_vali_data = pd.DataFrame(mice_vali_data, columns=['X_1','X_2','Z_1','Z_2','Z_3','Z_star_1','Z_star_2','Z_star_3','U','Y'])\n",
    "\n",
    "\n",
    "    train_data = pd.DataFrame(mice_train_data, columns=['X_1','X_2','Z_1','Z_2','Z_3','Z_star_1','Z_star_2','Z_star_3','U','Y'])\n",
    "    vali_data = pd.DataFrame(mice_vali_data, columns=['X_1','X_2','Z_1','Z_2','Z_3','Z_star_1','Z_star_2','Z_star_3','U','Y'])\n",
    "    test_data = pd.DataFrame(test_data, columns=['X_1','X_2','Z_1','Z_2','Z_3','U','Y'])    \n",
    "    \n",
    "    LR_target_measures = train_LR_and_get_predictions_fnc(mice_train_data = mice_train_data, mice_vali_data = mice_vali_data, test_data = test_data)\n",
    "    RF_target_measures = train_RF_and_get_predictions_fnc(train_data = train_data, vali_data = vali_data, test_data = test_data)\n",
    "    BT_target_measures = train_BT_and_get_predictions_fnc(train_data = train_data, vali_data = vali_data, test_data = test_data)\n",
    "    \n",
    "    Y = test_data['Y'].values\n",
    "    \n",
    "    return pd.DataFrame(LR_target_measures +  RF_target_measures + BT_target_measures)\n",
    "\n",
    "single_run_fnc(\n",
    "        N_test = 30000,\n",
    "        N_train = 30000,\n",
    "        N_vali = 10000,\n",
    "        gamma0 = 0,\n",
    "        gamma_X1 = 0.5,\n",
    "        gamma_X2 = 0.5,\n",
    "        gamma_U = 0.5, \n",
    "        W = np.array([[0.5, 0], [0.5, 0.5], [0, 0.5]]),\n",
    "        b = np.array([1, 1, 1]),\n",
    "        R1_prev = 0.5,\n",
    "        beta0 = 0,\n",
    "        beta_X1 = 0,\n",
    "        beta_X2 = 0,\n",
    "        beta_U = 0,\n",
    "        stddev = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_simulation_parameters_and_target_measures_fnc(dag_type: str,\n",
    "                                                       iteration: int,\n",
    "                                                       parameters: dict,\n",
    "                                                       target_measures: pd.DataFrame,\n",
    "                                                       column_names: list[str],\n",
    "                                                       file_path: str):\n",
    "    \"\"\"\n",
    "    Add the DAG type, iteration, and all the parameters as new columns alongside the target measures.\n",
    "    Then save to the file.\n",
    "    \"\"\"\n",
    "    dataframe_to_save = target_measures.copy()\n",
    "    dataframe_to_save[\"DAG type\"] = dag_type\n",
    "    dataframe_to_save[\"iteration\"] = iteration\n",
    "    for parameter_name, parameter_value in parameters.items():\n",
    "        dataframe_to_save[parameter_name] = str(parameter_value)\n",
    "    \n",
    "    # Ensure that dataframe has all the expected columns in the expected order\n",
    "    for column in column_names:\n",
    "        if column not in dataframe_to_save.columns:\n",
    "            print(f\"Warning! We didn't find column {column}\")\n",
    "            dataframe_to_save[column] = \"unknown\"\n",
    "    \n",
    "    dataframe_to_save_ordered = dataframe_to_save.loc[:, column_names]\n",
    "    assert (dataframe_to_save_ordered.columns == column_names).all()\n",
    "    \n",
    "    print(\"We're saving!\")\n",
    "    # Save to CSV\n",
    "    dataframe_to_save_ordered.to_csv(file_path, mode=\"a\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_run_fnc(n_iterations = 2, output_file_path: str = \"test_output.csv\"):\n",
    "                                                                                                                        \n",
    "    # Define defaults\n",
    "    default_parameters = {\n",
    "        \"N_test\": 30000,\n",
    "        \"N_train\": 30000,\n",
    "        \"N_vali\": 10000,\n",
    "        \"gamma0\": 0, \n",
    "        \"gamma_X1\": 1,\n",
    "        \"gamma_X2\": 1,\n",
    "        \"gamma_U\": 1,\n",
    "        \"W\": np.array([[0.5, 0], [0.5, 0.5], [0, 0.5]]),\n",
    "        \"b\": np.array([0, 0, 0]), \n",
    "        \"R1_prev\": 0.5,\n",
    "        \"stddev\": 0.5\n",
    "        }\n",
    "    \n",
    "     # Define column names for later saving, initialise file with header\n",
    "    column_names = [\"N_test\", \n",
    "                    \"N_train\", \n",
    "                    \"N_vali\", \n",
    "                    \"gamma0\", \n",
    "                    \"gamma_X1\", \n",
    "                    \"gamma_X2\", \n",
    "                    \"gamma_U\", \n",
    "                    \"W\", \n",
    "                    \"b\", \n",
    "                    \"R1_prev\", \n",
    "                    \"stddev\",\n",
    "                    \"beta0\",\n",
    "                    \"beta_X1\",\n",
    "                    \"beta_X2\",\n",
    "                    \"beta_U\",\n",
    "                    \"dataset\", \n",
    "                    \"model\", \n",
    "                    \"Cal_Plot\",\n",
    "                    \"O_E\", \n",
    "                    \"AUC\", \n",
    "                    \"Brier\"]\n",
    "    \n",
    "    print(f\"Saving outputs to {output_file_path}. Column names: {column_names}.\")\n",
    "    with open(output_file_path, \"w\") as f:\n",
    "        f.write(\",\".join(column_names) + \"\\n\")\n",
    "    \n",
    "    # Create MCAR parameters\n",
    "    MCAR_parameter_setting = []\n",
    "    for beta_X1 in [0.5, 1]:\n",
    "        for beta_X2 in [0.5, 1]:\n",
    "            for beta_U in [0.5, 1]:\n",
    "                single_MCAR_parameter_setting = {\"beta0\": 0, \"beta_X1\": 0, \"beta_X2\": 0, \"beta_U\": 0}\n",
    "                MCAR_parameter_setting.append(single_MCAR_parameter_setting)\n",
    "    \n",
    "    \n",
    "    # Create MAR parameters\n",
    "    MAR_parameter_setting = []\n",
    "    for beta_X2 in [0.5, 1]:\n",
    "        single_MAR_parameter_setting = {\"beta0\": 0, \"beta_X1\": 0, \"beta_X2\": beta_X2, \"beta_U\": 0}\n",
    "        MAR_parameter_setting.append(single_MAR_parameter_setting)\n",
    "\n",
    "   \n",
    "   # Create MNAR1 parameters\n",
    "   # Beta_X1 and U should be non-zero\n",
    "    MNAR1_parameter_setting = []\n",
    "    for beta_X1 in [0.5, 1]:\n",
    "        single_MNAR1_parameter_setting = {\"beta0\": 0, \"beta_X1\": beta_X1, \"beta_X2\": 0, \"beta_U\": 0}\n",
    "        for beta_U in [0.5, 1]: \n",
    "            single_MNAR1_parameter_setting = {\"beta0\": 0, \"beta_X1\": beta_X1, \"beta_X2\": 0, \"beta_U\": beta_U}\n",
    "            MNAR1_parameter_setting.append(single_MNAR1_parameter_setting)\n",
    "    # MNAR1_parameter_setting should have 4 entries in it\n",
    "    assert len(MNAR1_parameter_setting) == 4\n",
    "       \n",
    "\n",
    "   # Create MNAR2 parameters\n",
    "   # Beta_X1 is 0, but beta_U is non-zero\n",
    "    MNAR2_parameter_setting = []\n",
    "    for beta_U in [0.5, 1]: \n",
    "        single_MNAR2_parameter_setting = {\"beta0\": 0, \"beta_X1\": 0, \"beta_X2\": 0, \"beta_U\": beta_U}\n",
    "        MNAR2_parameter_setting.append(single_MNAR2_parameter_setting)\n",
    "    # This list should have 2 values\n",
    "    assert len(MNAR2_parameter_setting) == 2\n",
    "\n",
    "\n",
    "   # Create MNAR3 parameters\n",
    "   # Beta_X1, Beta_X2, and Beta_U are non-zero\n",
    "    MNAR3_parameter_setting = []\n",
    "    for beta_X1 in [0.5, 1]:\n",
    "        for beta_X2 in [0.5, 1]:\n",
    "            for beta_U in [0.5, 1]: \n",
    "                single_MNAR3_parameter_setting = {\"beta0\": 0, \"beta_X1\": beta_X1, \"beta_X2\": beta_X2, \"beta_U\": beta_U}\n",
    "                MNAR3_parameter_setting.append(single_MNAR3_parameter_setting)\n",
    "    # This list should have 8 values in it\n",
    "    assert len(MNAR3_parameter_setting) == 8\n",
    "\n",
    "\n",
    "    # Create a list with all the Ws of interest\n",
    "    W_options = [] # possibly use product here\n",
    "\n",
    "    W_20 = 0\n",
    "    W_01 = 0\n",
    "    W_entry_options = [0.5, 1.0]\n",
    "    for W_00 in W_entry_options:\n",
    "        for W_10 in W_entry_options:\n",
    "            for W_11 in W_entry_options:\n",
    "                for W_21 in W_entry_options:\n",
    "                    W = np.array([[W_00, W_01], [W_10, W_11], [W_20, W_21]])\n",
    "                    W_options.append(W)\n",
    "    # this should have 16 entries in it\n",
    "    assert len(W_options) == 16\n",
    "\n",
    "#create dictionaries to vary individual parameters excluding betas which are part of the DAG scenarios above (eg W, R1_prev, stddev, gammas)\n",
    "\n",
    "    non_beta_parameter_options = []\n",
    "    for gamma_X1 in [0.5, 1]:\n",
    "        for gamma_X2 in [0.5, 1]:\n",
    "            for gamma_U in [0.5, 1]:\n",
    "                for W in W_options:\n",
    "                    for b in [np.array([0, 0, 0]), np.array([1, 1, 1])]:\n",
    "                                parameters = {\n",
    "                                              \"gamma_X1\": gamma_X1, \n",
    "                                              \"gamma_X2\": gamma_X2, \n",
    "                                              \"gamma_U\": gamma_U, \n",
    "                                              \"W\": W, \n",
    "                                              \"b\": b, \n",
    "                                              }\n",
    "                                non_beta_parameter_options.append(parameters)\n",
    "                                # assert len(non_beta_parameter_options) == 144 * 16 #2304\n",
    "    # Now JUST vary stddev\n",
    "    for stddev in [0.1, 0.5, 1]:\n",
    "        parameters = {\"stddev\": stddev}\n",
    "        non_beta_parameter_options.append(parameters)\n",
    "\n",
    "    for R1_prev in [0.1, 0.2, 0.5]:\n",
    "        parameteres = {\"R1_prev\": R1_prev}\n",
    "        non_beta_parameter_options.append(parameteres)\n",
    "    \n",
    "\n",
    "\n",
    "    # Combine all the scenarios\n",
    "    DAG_settings_to_explore = {\"MCAR\": MCAR_parameter_setting,\n",
    "                               \"MAR\": MAR_parameter_setting,\n",
    "                               \"MNAR1\": MNAR1_parameter_setting,\n",
    "                               \"MNAR2\": MNAR2_parameter_setting,\n",
    "                               \"MNAR3\": MNAR3_parameter_setting}\n",
    "    [\n",
    "         MCAR_parameter_setting, \n",
    "         MAR_parameter_setting, \n",
    "         MNAR1_parameter_setting, \n",
    "         MNAR2_parameter_setting, \n",
    "         MNAR3_parameter_setting\n",
    "         ]\n",
    "\n",
    "    print(DAG_settings_to_explore)\n",
    "\n",
    "    # Two things to be aware of:\n",
    "    # - DAG_settings_to_explore is current a LIST of LISTS\n",
    "    # - We are passing a dictionary to single_run_fnc but it expects a bunch of parameters\n",
    "    # - Target measures is a Pandas dataframe\n",
    "    # How many simulations are we going to run?\n",
    "\n",
    "    total_dag_settings = sum([len(dag_setting_list) for dag_setting_list in DAG_settings_to_explore.values()])\n",
    "    total_simulations = total_dag_settings * len(non_beta_parameter_options) * n_iterations\n",
    "    print(f\"About to run {total_simulations} simulations\")\n",
    "\n",
    "    return False\n",
    "    \n",
    "    # For each DAG setting in our list of DAG settings:\n",
    "    for DAG_setting_name, DAG_setting_list in DAG_settings_to_explore.items():\n",
    "        print(f\"Exploring DAGs of the type {DAG_setting_name}\")\n",
    "        for DAG_setting in DAG_setting_list:\n",
    "            # Loop over all the \"non-beta parameters\" to vary\n",
    "            for non_beta_parameter_setting in non_beta_parameter_options:       # we have 288 here, so 17 * 288 in total\n",
    "                # Create the full set of parameters to give to the simulation\n",
    "                # We start with the default parameters (dictionary)\n",
    "                this_simulation_parameters = {k: v for k, v in default_parameters.items()}\n",
    "                # We use the DAG_setting to set the betas\n",
    "                for parameter, new_value in DAG_setting.items():\n",
    "                    print(f\"Setting parameter {parameter} to be value {new_value}\")\n",
    "                    this_simulation_parameters[parameter] = new_value\n",
    "                # We use the non_beta_paramter_setting to set everything else\n",
    "                for parameter, new_value in non_beta_parameter_setting.items():\n",
    "                    print(f\"Setting parameter {parameter} to be value {new_value}\")\n",
    "                    this_simulation_parameters[parameter] = new_value\n",
    "                print(f\"Running simulation with parameters {this_simulation_parameters}\")\n",
    "\n",
    "                # And run the simulation for those\n",
    "                for iteration in range(n_iterations):\n",
    "                    t0 = time()\n",
    "                    target_measures = single_run_fnc(\n",
    "                                                    N_test = this_simulation_parameters[\"N_test\"],\n",
    "                                                    N_train = this_simulation_parameters[\"N_train\"],\n",
    "                                                    N_vali = this_simulation_parameters[\"N_vali\"],\n",
    "                                                    gamma0 = this_simulation_parameters[\"gamma0\"],\n",
    "                                                    gamma_X1 = this_simulation_parameters[\"gamma_X1\"],\n",
    "                                                    gamma_X2 = this_simulation_parameters[\"gamma_X2\"],\n",
    "                                                    gamma_U = this_simulation_parameters[\"gamma_U\"],\n",
    "                                                    beta0 = this_simulation_parameters[\"beta0\"],\n",
    "                                                    beta_X1 = this_simulation_parameters[\"beta_X1\"],\n",
    "                                                    beta_X2 = this_simulation_parameters[\"beta_X2\"],\n",
    "                                                    beta_U = this_simulation_parameters[\"beta_U\"],\n",
    "                                                    W = this_simulation_parameters[\"W\"],\n",
    "                                                    b = this_simulation_parameters[\"b\"],\n",
    "                                                    R1_prev = this_simulation_parameters[\"R1_prev\"],\n",
    "                                                    stddev = this_simulation_parameters[\"stddev\"]\n",
    "                                                    )\n",
    "                    elapsed_time = time() - t0\n",
    "                    print(f\"Single iteration took {elapsed_time} seconds\")\n",
    "                \n",
    "                    print(this_simulation_parameters)\n",
    "                \n",
    "                    \n",
    "                    # Save simulation parameters and target measures to file\n",
    "                    save_simulation_parameters_and_target_measures_fnc(dag_type = DAG_setting_name,\n",
    "                                                                       column_names = column_names,             \n",
    "                                                                       iteration = iteration,\n",
    "                                                                       parameters = this_simulation_parameters,\n",
    "                                                                       target_measures = target_measures,\n",
    "                                                                       file_path = output_file_path)\n",
    "                   \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_run_fnc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "701d4f28dcd0866722f5108a3a4cbcd08882d26398b6d44117e791d7b8102912"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
